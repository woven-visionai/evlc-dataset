<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>E-VLC Dataset</title>
    <meta name="author" content="E-VLC Dataset" />
    <meta name="description" content="A Real-World Dataset for Event-based Visible Light Communication And Localization" />
    <meta name="keywords" content="E-VLC, Event cameras, Visible Light Communication, Active markers, Dataset" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="E-VLC Dataset" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="E-VLC Dataset | Home" />
    <meta property="og:url" content="http://localhost:5500/evlc-dataset/" />
    <meta property="og:description" content="A Real-World Dataset for Event-based Visible Light Communication And Localization." />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Home" />
    <meta name="twitter:description" content="A Real-World Dataset for Event-based Visible Light Communication And Localization." />
    
    

    <!-- Schema.org -->
    <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "E-VLC Dataset"
        },
        "url": "http://localhost:5500/evlc-dataset/",
        "@type": "WebSite",
        "description": "A Real-World Dataset for Event-based Visible Light Communication And Localization",
        "headline": "Home",
        "sameAs": ["https://woven-visionai.github.io/evlc-dataset/"],
        "name": "E-VLC Dataset",
        "@context": "https://schema.org"
      }
    </script>

    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/PASTIE.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
        
    <link rel="stylesheet" href="/evlc-dataset/assets/css/main.css">
    <link rel="canonical" href="http://localhost:5500/evlc-dataset/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- Home -->
              <li class="nav-item">
                <a class="nav-link" href="/evlc-dataset/">Home<span class="sr-only">(current)</span></a>
              </li>
              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/evlc-dataset/about/">About</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/evlc-dataset/download/">Download</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="https://github.com/woven-visionai/evlc-dataset/issues" target="_blank" rel="noopener noreferrer">Contact Us</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Recording Setup</h1>
            <p class="post-description"></p>
          </header>

<article>

  <div class="competition-sqe-title">VLC Receiver</div>
  <p><br></p>
  <div class="row">
      <div class="col-sm mt-3 mt-md-0">
        <picture>
          <!-- Fallback to the original file -->
          <div style="text-align: center;">
            <p><img src="/evlc-dataset/assets/img/about.png" alt="receiver" style="max-width:100%;"></p>
          </div>
        </picture>
      </div>
  </div>

<p>
  The E-VLC dataset focuses on the scenes where the receiver (cameras) moves at a walking speed, while the scene (including LED markers) is static.
  To this end, we build a custom mobile recording system equipped with two high-resolution cameras, a tablet, and a trigger box, enabling us to achieve high-quality calibration and synchronization.
  Our custom-built system consists of <a href="https://www.prophesee.ai/event-camera-evk4/" target="_blank" rel="noopener noreferrer">Prophesee EVK-4, 1280 x 720 pix</a>
  and <a href="https://www.baslerweb.com/en/shop/aca1300-200um/" target="_blank" rel="noopener noreferrer">Basler acA1300-200um, 1280 x 1024 pix</a>.  
  Both cameras have a slight baseline (i.e., stereo settings) and are recorded to a tablet (Surface 11 Pro, Ubuntu 22.02) via USB cables.
</p>
<p>
  The frames are hardware-triggered and record videos at 40fps.
  The trigger box sends synchronization pulses at 120Hz to three different destinations:
  the two cameras and an external motion capture (OptiTrack).
  We design one of the trigger cables to be 10m so that it allows the recording device to move inside the motion capture system,
  which provides GT positions of the camera and LED markers at sub-millimeter accuracy at 100Hz.  
  Notice that there are small offsets between the cameras and the markers of the motion capture.
</p>

<p><br></p>

<div class="competition-sqe-title">VLC Transmitter</div>
<p><br></p>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
      <picture>
        <!-- Fallback to the original file -->
        <div style="text-align: center;">
          <p><img src="/evlc-dataset/assets/img/markers.png" alt="transmitter" style="max-width:100%;"></p>
        </div>
      </picture>
    </div>
</div>

<p>
  As LED markers (Orange circles), we use bullet-shaped LEDs (OSPG5111A, Green, 0.1W) with a custom microcontroller that controls the LED modulation.
  One microcontroller controls five LEDs with different blink patterns, whose timings (temporal resolution) are synchronized.
  The data transmitted are a few bytes of numbers (IDs), and each LED repeats the assigned blink pattern, which is typically around 10ms.
  In total, we use 40 LED markers (i.e., 8 microcontrollers), all of which transmit different IDs.
  The markers are attached to different objects, such as boxes and tables, as well as an Aruco marker (printed on A1 size) to benchmark with frame-based localization methods. 
  The precise LED positions are measured with the motion capture system before the camera recordings (Yellow circles).
</p>
  
  <!-- Several prior work have proposed modulation protocols (see \cref{sec:related}).
  Among them, we choose the interval-based protocol,
  since ($i$) it is robust among others tested,
  ($ii$) it is popularly used (e.g., supported by Prophesee's Metavision SDK \cite{MetavisionLED}),
  and ($iii$) it is robust against the tail-event effect of negative events in dark scenes, since it relies on positive (ON) events only.
  The time-interval protocol parameters consist of the fundamental frequency $\baseF$, the binary patterns, and the start pattern.
  In this work, we set $\baseF = 5$~kHz, binary ``$0$'' as $1/\baseF$, ``$1$'' as $2/\baseF$, and start as $3/\baseF$ that are distinguished with $1/\baseF$ lighting off. -->
  

<p><br></p>

</article>

  <!-- Footer -->    
  <footer class="fixed-bottom">
    <div class="container mt-0" style="width:100%;text-align:center;">
      Â© 2025 Woven by Toyota, Inc. <a href="https://woven.toyota/en/privacy-notice/" target="_blank" rel="noopener noreferrer">Privacy Notice</a>
    </div>
  </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/evlc-dataset/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/evlc-dataset/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/evlc-dataset/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

